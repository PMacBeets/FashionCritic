{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-373108ef11fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfashion_mnist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "print('x_train.shape:', x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-4b8651649529>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ],
     "output_type": "error"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for index in range(10):\n",
    "  plt.subplot(2, 5, index+1)\n",
    "  plt.imshow(x_train[index], vmin=0, vmax=255)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-38cb71084295>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Cast Data so Tf can manipulate matrices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# Cast Data so Tf can manipulate matrices\n",
    "x_train = tf.cast(x_train, dtype=tf.float32)\n",
    "y_train = tf.cast(y_train, dtype=tf.int32)\n",
    "x_test = tf.cast(x_test, dtype=tf.float32)\n",
    "y_test = tf.cast(y_test, dtype=tf.int32)\n",
    "\n",
    "# The raw data are in range [0, 255], we scale it to [-1, 1].\n",
    "x_train = (x_train - 127.5) / 127.5\n",
    "x_test = (x_test - 127.5) / 127.5\n",
    "\n",
    "#one hot\n",
    "num_class = tf.reduce_max(y_train) + 1\n",
    "y_tr = tf.one_hot(tf.squeeze(y_train), num_class)\n",
    "y_te = tf.one_hot(tf.squeeze(y_test), num_class)\n",
    "\n",
    "\n",
    "\n",
    "print('x_train.shape:', x_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-5ca94e3aff9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# does not have the channel dimension, so we expand the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# TF supports two image format: NCHW (channels_first) and NHWC (channels_last), both are fine.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# convert to shape NCHW: 60000x1x28x28\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    " # ONLY RUN ONCE!! \n",
    "    \n",
    "# The data loaded from TF is in tensor format. Due to its greyscale nature, it \n",
    "# does not have the channel dimension, so we expand the data\n",
    "# TF supports two image format: NCHW (channels_first) and NHWC (channels_last), both are fine.\n",
    "x_train = tf.expand_dims(x_train, axis=1)  # convert to shape NCHW: 60000x1x28x28\n",
    "x_test = tf.expand_dims(x_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"plainCNN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv2D)               (None, 1, 14, 16)         4048      \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 1, 7, 32)          4640      \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 1, 4, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max-pool (GlobalMaxPooling2D (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 27,834\n",
      "Trainable params: 27,834\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#create basic model\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# 2.2 build the model\n",
    "model = tf.keras.Sequential(name='plainCNN')\n",
    "# if we want to add L2 regularization, we could pass \n",
    "# \"kernel_regularizer=tf.keras.regularizers.l2(l=0.01)\"\n",
    "# to layers.Conv2D\n",
    "model.add(layers.Conv2D(\n",
    "    16, kernel_size=3, strides=2, padding='same', data_format='channels_last', \n",
    "    activation='relu', input_shape=(1,28,28), name='conv1'))\n",
    "model.add(layers.Conv2D(\n",
    "    32, kernel_size=3, strides=2, padding='same', data_format='channels_last', \n",
    "    activation='relu', name='conv2'))\n",
    "model.add(layers.Conv2D(\n",
    "    64, kernel_size=3, strides=2, padding='same', data_format='channels_last', \n",
    "    activation='relu', name='conv3'))\n",
    "model.add(layers.GlobalMaxPool2D(data_format='channels_last', name='max-pool'))\n",
    "model.add(layers.Dense(10, activation=None, name='output'))  # None means no activation or linear\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.optimizer_v2.learning_rate_schedule.PiecewiseConstantDecay object at 0xbd202b208>\n",
      "Model compiled.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers.schedules import PiecewiseConstantDecay\n",
    "\n",
    "batch_size = 64\n",
    "num_instance = 50000\n",
    "# Let's say, if we want to decay the learning rate at 40, 80, 160 epochs\n",
    "boundary = (40*num_instance // batch_size, 80*num_instance // batch_size, 160*num_instance // batch_size)\n",
    "value = (1e-3, 3e-4, 1e-4, 3e-5)\n",
    "learning_rate = PiecewiseConstantDecay(boundary, value)\n",
    "print(learning_rate)\n",
    "\n",
    "# in the loss, from_logits=True because we use linear activation at the last layer\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "print('Model compiled.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7ffc810544f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# Train the model\n",
    "epochs = 60\n",
    "history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NewCheckpoint\n"
     ]
    }
   ],
   "source": [
    "print(\"NewCheckpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1_kernal",
   "language": "python",
   "name": "env1_kernal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
